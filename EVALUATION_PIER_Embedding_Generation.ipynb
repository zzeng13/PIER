{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we generated idiom embeddings using the trained PIER+ model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec56904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import trange\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "\n",
    "from src.utils.data_util import  DataHandlerCLS\n",
    "from src.train_valid_test_step import *\n",
    "from config import Config as config\n",
    "from src.model.bart_adapters import BartAdapterCombined\n",
    "from src.model.bert_adapters import  BertAdapter\n",
    "from src.utils.model_util import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffa87b",
   "metadata": {},
   "source": [
    "## Load PIER+ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42830970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of idioms: 1521\n",
      "Training dataset size: 32693\n",
      "Validation dataset size: 4102\n",
      "Testing dataset size: 4080\n",
      "Load base model from facebook/bart-base\n",
      "=> Initializing Adapters with Fusion Module...\n",
      "\n",
      "[COMPOSITIONAL MODULE]: \n",
      "==> Using BART output as compositional embedding!\n",
      "\n",
      "[NON-COMPOSITIONAL MODULE]: \n",
      "==> Loading Adapter from /home/zzeng/workspace/UIUC_research/RepresentationLearning/models/PIER/checkpoints/bart-adapters_non-compositional_magpie_random-GIEA/best/\n",
      "==> Non-compositional adapter loaded!\n",
      "\n",
      "[COMBINED MODULE]: \n",
      "==> Adding fusion module!\n",
      "Fuse[compositional, non-compositional]\n",
      "==> Loading Adapter Fusion from /home/zzeng/workspace/UIUC_research/RepresentationLearning/models/PIER/checkpoints/bart-adapters_fusion_magpie_random-PIER/best/\n",
      "==>  Adapter Fusion Loaded!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartAdapterCombined(\n",
       "  (model): BartForConditionalGeneration(\n",
       "    (model): BartModel(\n",
       "      (shared): Embedding(50265, 768, padding_idx=1)\n",
       "      (encoder): BartEncoder(\n",
       "        (invertible_adapters): ModuleDict()\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): BartSelfAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): BartOutputAdaptersModule(\n",
       "              (adapters): ModuleDict(\n",
       "                (compositional): Adapter()\n",
       "                (non-compositional): Adapter(\n",
       "                  (non_linearity): Activation_Function_Class()\n",
       "                  (adapter_down): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                    (1): Activation_Function_Class()\n",
       "                  )\n",
       "                  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (adapter_fusion_layer): ModuleDict(\n",
       "                (compositional,non-compositional): BertFusion(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (1): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): BartSelfAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): BartOutputAdaptersModule(\n",
       "              (adapters): ModuleDict(\n",
       "                (compositional): Adapter()\n",
       "                (non-compositional): Adapter(\n",
       "                  (non_linearity): Activation_Function_Class()\n",
       "                  (adapter_down): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                    (1): Activation_Function_Class()\n",
       "                  )\n",
       "                  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (adapter_fusion_layer): ModuleDict(\n",
       "                (compositional,non-compositional): BertFusion(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (2): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): BartSelfAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): BartOutputAdaptersModule(\n",
       "              (adapters): ModuleDict(\n",
       "                (compositional): Adapter()\n",
       "                (non-compositional): Adapter(\n",
       "                  (non_linearity): Activation_Function_Class()\n",
       "                  (adapter_down): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                    (1): Activation_Function_Class()\n",
       "                  )\n",
       "                  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (adapter_fusion_layer): ModuleDict(\n",
       "                (compositional,non-compositional): BertFusion(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (3): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): BartSelfAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): BartOutputAdaptersModule(\n",
       "              (adapters): ModuleDict(\n",
       "                (compositional): Adapter()\n",
       "                (non-compositional): Adapter(\n",
       "                  (non_linearity): Activation_Function_Class()\n",
       "                  (adapter_down): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                    (1): Activation_Function_Class()\n",
       "                  )\n",
       "                  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (adapter_fusion_layer): ModuleDict(\n",
       "                (compositional,non-compositional): BertFusion(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (4): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): BartSelfAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): BartOutputAdaptersModule(\n",
       "              (adapters): ModuleDict(\n",
       "                (compositional): Adapter()\n",
       "                (non-compositional): Adapter(\n",
       "                  (non_linearity): Activation_Function_Class()\n",
       "                  (adapter_down): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                    (1): Activation_Function_Class()\n",
       "                  )\n",
       "                  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (adapter_fusion_layer): ModuleDict(\n",
       "                (compositional,non-compositional): BertFusion(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (5): BartEncoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): BartSelfAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): BartOutputAdaptersModule(\n",
       "              (adapters): ModuleDict(\n",
       "                (compositional): Adapter()\n",
       "                (non-compositional): Adapter(\n",
       "                  (non_linearity): Activation_Function_Class()\n",
       "                  (adapter_down): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                    (1): Activation_Function_Class()\n",
       "                  )\n",
       "                  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (adapter_fusion_layer): ModuleDict(\n",
       "                (compositional,non-compositional): BertFusion(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): BartDecoder(\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "        (layers): ModuleList(\n",
       "          (0): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): BartSelfAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): BartOutputAdaptersModule(\n",
       "              (adapters): ModuleDict(\n",
       "                (compositional): Adapter()\n",
       "                (non-compositional): Adapter(\n",
       "                  (non_linearity): Activation_Function_Class()\n",
       "                  (adapter_down): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                    (1): Activation_Function_Class()\n",
       "                  )\n",
       "                  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (adapter_fusion_layer): ModuleDict(\n",
       "                (compositional,non-compositional): BertFusion(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (cross_attention_adapters): BartCrossAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (1): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): BartSelfAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): BartOutputAdaptersModule(\n",
       "              (adapters): ModuleDict(\n",
       "                (compositional): Adapter()\n",
       "                (non-compositional): Adapter(\n",
       "                  (non_linearity): Activation_Function_Class()\n",
       "                  (adapter_down): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                    (1): Activation_Function_Class()\n",
       "                  )\n",
       "                  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (adapter_fusion_layer): ModuleDict(\n",
       "                (compositional,non-compositional): BertFusion(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (cross_attention_adapters): BartCrossAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (2): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): BartSelfAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): BartOutputAdaptersModule(\n",
       "              (adapters): ModuleDict(\n",
       "                (compositional): Adapter()\n",
       "                (non-compositional): Adapter(\n",
       "                  (non_linearity): Activation_Function_Class()\n",
       "                  (adapter_down): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                    (1): Activation_Function_Class()\n",
       "                  )\n",
       "                  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (adapter_fusion_layer): ModuleDict(\n",
       "                (compositional,non-compositional): BertFusion(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (cross_attention_adapters): BartCrossAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (3): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): BartSelfAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): BartOutputAdaptersModule(\n",
       "              (adapters): ModuleDict(\n",
       "                (compositional): Adapter()\n",
       "                (non-compositional): Adapter(\n",
       "                  (non_linearity): Activation_Function_Class()\n",
       "                  (adapter_down): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                    (1): Activation_Function_Class()\n",
       "                  )\n",
       "                  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (adapter_fusion_layer): ModuleDict(\n",
       "                (compositional,non-compositional): BertFusion(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (cross_attention_adapters): BartCrossAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (4): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): BartSelfAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): BartOutputAdaptersModule(\n",
       "              (adapters): ModuleDict(\n",
       "                (compositional): Adapter()\n",
       "                (non-compositional): Adapter(\n",
       "                  (non_linearity): Activation_Function_Class()\n",
       "                  (adapter_down): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                    (1): Activation_Function_Class()\n",
       "                  )\n",
       "                  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (adapter_fusion_layer): ModuleDict(\n",
       "                (compositional,non-compositional): BertFusion(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (cross_attention_adapters): BartCrossAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (5): BartDecoderLayer(\n",
       "            (self_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BartAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention_adapters): BartSelfAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (output_adapters): BartOutputAdaptersModule(\n",
       "              (adapters): ModuleDict(\n",
       "                (compositional): Adapter()\n",
       "                (non-compositional): Adapter(\n",
       "                  (non_linearity): Activation_Function_Class()\n",
       "                  (adapter_down): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=48, bias=True)\n",
       "                    (1): Activation_Function_Class()\n",
       "                  )\n",
       "                  (adapter_up): Linear(in_features=48, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (adapter_fusion_layer): ModuleDict(\n",
       "                (compositional,non-compositional): BertFusion(\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "            (cross_attention_adapters): BartCrossAttentionAdaptersModule(\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "              (adapter_flow_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (invertible_adapters): ModuleDict()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       "  )\n",
       "  (cosine_loss): CosineEmbeddingLoss()\n",
       "  (nll_loss): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "data_handler = DataHandlerCLS()\n",
    "\n",
    "# Manage and initialize model\n",
    "# ---------------------------------------------------------------------------------\n",
    "# Initialize model\n",
    "model = BartAdapterCombined(data_handler.config)\n",
    "model.to(config.DEVICE)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a3a24",
   "metadata": {},
   "source": [
    "## Generate IE embeddings from  PIER+ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fcf2211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction on test set\n",
    "def mean_pooling(token_embeddings, attention_mask):\n",
    "    # token_embeddings: [batch_size, max_seq_len, hidden_dim]\n",
    "    # token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "idioms2embed = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9d98ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "model.eval()    \n",
    "            \n",
    "count = 0        \n",
    "bbar = tqdm(enumerate(data_handler.validset_generator),\n",
    "                ncols=100, leave=False, total=data_handler.config.num_batch_valid)\n",
    "\n",
    "for idx, data in bbar:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # model forward pass to compute loss\n",
    "        outputs = model.model(**data['inputs'])\n",
    "    embeds = model.mean_pooling(outputs.last_hidden_state, data['phrase_masks'])\n",
    "    embeds = embeds.detach().cpu().numpy()\n",
    "    idioms = data['idioms']\n",
    "    labels = data['labels']\n",
    "    for i, idiom in enumerate(idioms): \n",
    "        if labels[i] == 1: \n",
    "            count +=1\n",
    "            if idiom not in idioms2embed: \n",
    "                idioms2embed[idiom] = []\n",
    "            idioms2embed[idiom].append(embeds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed671047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of idioms with embeddings: 927\n"
     ]
    }
   ],
   "source": [
    "idioms2embed = {k: np.mean(v, 0) for k, v in idioms2embed.items()}      \n",
    "idioms = [k for k in idioms2embed.keys()]\n",
    "print(\"Number of idioms with embeddings:\", len(idioms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce9b5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate similarity matrix among the IEs and find top-k similar IEs\n",
    "embed_matrix = np.array([idioms2embed[k] for k in idioms])\n",
    "embed_distances = cosine_distances(embed_matrix, embed_matrix)\n",
    "embed_distances_argsort = np.argsort(embed_distances, axis=- 1)\n",
    "k = 20\n",
    "idioms_to_k_similar_idioms = {}\n",
    "for idx, idiom in enumerate(idioms):\n",
    "    idioms_to_k_similar_idioms[idiom] = [[idioms[i], embed_distances[idx][i]] for i in embed_distances_argsort[idx][:k].tolist()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73899876",
   "metadata": {},
   "source": [
    "## Show Example Similar IEs in the embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd3d1874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['come to think of it',\n",
       " 'in light of',\n",
       " 'get stuck in',\n",
       " 'keep a straight face',\n",
       " 'work to rule']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idioms[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b628b6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['streets ahead', 0.0],\n",
       " ['within an ace of', 0.2657256],\n",
       " ['thin as a rake', 0.30747408],\n",
       " ['by a long chalk', 0.3227167],\n",
       " ['writ large', 0.3315162],\n",
       " ['out of this world', 0.3358181],\n",
       " ['hands down', 0.33906674],\n",
       " ['see eye to eye', 0.34751314],\n",
       " ['sure as eggs is eggs', 0.35784304],\n",
       " ['plain as a pikestaff', 0.35981655],\n",
       " ['for my money', 0.36552393],\n",
       " ['to die for', 0.36816168],\n",
       " ['to a T', 0.3721143],\n",
       " ['safe as houses', 0.37966752],\n",
       " ['like a bat out of hell', 0.38828826],\n",
       " ['piping hot', 0.38970816],\n",
       " ['tough as old boots', 0.3901841],\n",
       " ['far and away', 0.39553428],\n",
       " ['to all intents and purposes', 0.39599103],\n",
       " ['par for the course', 0.40517056]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idioms_to_k_similar_idioms[\"streets ahead\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61ac34a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['in the final analysis', 0.0],\n",
       " ['at the end of the day', 0.28763485],\n",
       " ['in light of', 0.3319497],\n",
       " ['all things being equal', 0.3830461],\n",
       " ['moment of truth', 0.41219515],\n",
       " ['the die is cast', 0.42674035],\n",
       " ['fall into place', 0.43464047],\n",
       " ['at a pinch', 0.4614349],\n",
       " ['true to form', 0.46339655],\n",
       " ['make the grade', 0.47711295],\n",
       " ['all over bar the shouting', 0.47885817],\n",
       " ['in a nutshell', 0.48183256],\n",
       " ['come out in the wash', 0.483594],\n",
       " ['without fail', 0.48694438],\n",
       " ['for my money', 0.49782443],\n",
       " ['up to scratch', 0.50782543],\n",
       " ['cut and dried', 0.508388],\n",
       " ['run the gamut', 0.50872135],\n",
       " ['bar none', 0.5088779],\n",
       " ['when all is said and done', 0.51531637]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idioms_to_k_similar_idioms[\"in the final analysis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34d18961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['see red', 0.0],\n",
       " ['go spare', 0.11840683],\n",
       " ['in stitches', 0.19273853],\n",
       " ['pissed off', 0.20207787],\n",
       " ['hot and bothered', 0.21367598],\n",
       " ['drive someone up the wall', 0.24889445],\n",
       " ['on the warpath', 0.2571019],\n",
       " ['high as a kite', 0.2678098],\n",
       " [\"knock someone's block off\", 0.27082056],\n",
       " [\"do someone's head in\", 0.27665257],\n",
       " [\"get under someone's skin\", 0.28626728],\n",
       " [\"get someone's goat\", 0.2875234],\n",
       " ['eat your heart out', 0.30015606],\n",
       " ['down in the dumps', 0.3022977],\n",
       " ['laugh like a drain', 0.30811393],\n",
       " ['touch a nerve', 0.3123538],\n",
       " ['scream blue murder', 0.31640375],\n",
       " ['spit the dummy', 0.3178118],\n",
       " [\"get up someone's nose\", 0.31822938],\n",
       " ['bang to rights', 0.32358658]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idioms_to_k_similar_idioms[\"see red\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea4b59",
   "metadata": {},
   "source": [
    "## Save Idiom Embeddings for implicit evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e043985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idioms2embed = {k:v.tolist() for k, v in idioms2embed.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7443109",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_json_file(path, data):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9bf839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json_file('./generated_embeddings/idiom2embed-PIER.json', idioms2embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82febe11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_adapters]",
   "language": "python",
   "name": "conda-env-pytorch_adapters-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
