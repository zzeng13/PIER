{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b26bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute performances for intrinsic evaluations with clustering \n",
    "# - homogeneity score (H-Score ↑) \n",
    "# - mean inter-group cosine distance (CosDist ↑)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1638ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import random\n",
    "import copy\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "# k-means and evaluate \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587feda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_lines(path_to_file): \n",
    "    with open(path_to_file) as f:\n",
    "        content = f.readlines()\n",
    "    f.close()\n",
    "    raw_data  = [json.loads(x) for x in content] \n",
    "    return raw_data\n",
    "\n",
    "def read_json_file(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def write_json_file(path, data):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b0552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of idioms: 1521\n",
      "Number of idioms with groups: 189\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the dictionaries\n",
    "combined_dict_embed = read_json_file('./fusion_analysis/magpie_idiom2embed_dictionary_google_wiki_single_meaning_cleaner_by_bart.json')\n",
    "print('Total Number of idioms: {}'.format(len(combined_dict_embed)))\n",
    "# 2. load idiom groups\n",
    "path_to_idiom_groups = './fusion_analysis/idiom_groups_by_meaning_20.txt'\n",
    "with open(path_to_idiom_groups) as f:\n",
    "    lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "idiom_groups = []\n",
    "for l in lines:\n",
    "    if l != '\\n':\n",
    "        l = l.strip()\n",
    "        if ':' in l: \n",
    "            cur_group_idx = int(l.split(':')[0].split(' ')[1])-1\n",
    "            cur_group_name = l.split(':')[1].strip()\n",
    "        else: \n",
    "            idiom_groups.append([l, cur_group_idx, cur_group_name])\n",
    "print(\"Number of idioms with groups:\", len(idiom_groups))\n",
    "# load idiom dictionary definitions\n",
    "idiom_dict = read_json_file('./fusion_analysis/magpie_idiom_dictionary_google_wiki_single_meaning.json')\n",
    "idiom_dict = {i[0]:idiom_dict[i[0]]  for i in idiom_groups}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a0688",
   "metadata": {},
   "source": [
    "## Clustering and compute scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224e271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_noncomp_dict= './generated_embeddings/idiom2embed-PIER.json'  # Generated from EVALUATION_IdiomAdapterEmbeddingSimilarity\n",
    "noncompcombined_dict_embed = read_json_file(path_to_noncomp_dict)\n",
    "N = 20  # Set to the number of groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74fc152a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idioms = [k for k in noncompcombined_dict_embed.keys()]\n",
    "test_idioms = [k  for k in idiom_groups if k[0] in noncompcombined_dict_embed]\n",
    "# produce cluster labels \n",
    "labels = np.array([k[1] for k in idiom_groups if k[0] in noncompcombined_dict_embed])\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6a4593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity score (H-score):\n",
      "0.6095213104253961\n"
     ]
    }
   ],
   "source": [
    "# Compute Homogeneity score\n",
    "embed_matrix = np.array([noncompcombined_dict_embed[k[0]] for k in idiom_groups if k[0] in noncompcombined_dict_embed])\n",
    "embed_matrix = np.asarray(embed_matrix, dtype='float64')\n",
    "embed_matrix.shape\n",
    "labels = np.array([k[1] for k in idiom_groups if  k[0] in noncompcombined_dict_embed])\n",
    "embed_matrix.shape\n",
    "embed_distances = cosine_distances(embed_matrix, embed_matrix)\n",
    "standardization = StandardScaler()\n",
    "# Run clustering\n",
    "X = embed_distances\n",
    "clustering = AgglomerativeClustering(affinity='precomputed', linkage='complete', n_clusters=N).fit(X)\n",
    "preds = clustering.labels_.tolist()\n",
    "print(\"Homogeneity score (H-score):\")\n",
    "print(homogeneity_score(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d47cd2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within group similarity (CosDist):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.183753855786771"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute within group similarity\n",
    "embed_sims = 1 - embed_distances\n",
    "sims_dict = {}\n",
    "for cur_idx in range(embed_sims.shape[0]): \n",
    "    sims_dict[cur_idx] = {'in': [], 'out': [], 'diff': 0.}\n",
    "    for nei_idx in range(embed_sims.shape[0]):\n",
    "        if cur_idx == nei_idx: \n",
    "            continue\n",
    "        else: \n",
    "            if labels[cur_idx] == labels[nei_idx]: \n",
    "                sims_dict[cur_idx]['in'].append(embed_sims[cur_idx, nei_idx])\n",
    "            else: \n",
    "                sims_dict[cur_idx]['out'].append(embed_sims[cur_idx, nei_idx])\n",
    "    sims_dict[cur_idx]['diff'] = np.mean(sims_dict[cur_idx]['in']) - np.mean(sims_dict[cur_idx]['out'])\n",
    "    \n",
    "sim_diff_dict = {}\n",
    "for cur_idx in sims_dict: \n",
    "    if labels[cur_idx] not in sim_diff_dict: \n",
    "        sim_diff_dict[labels[cur_idx]] = []\n",
    "    sim_diff_dict[labels[cur_idx]].append(sims_dict[cur_idx]['diff'])\n",
    "sim_diff_dict = {k: np.mean(v) for k, v in sim_diff_dict.items()}\n",
    "difference = np.mean([v for v in sim_diff_dict.values()])\n",
    "print(\"Within group similarity (CosDist):\")\n",
    "difference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
